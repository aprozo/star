{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilv6MKqrT9sd",
        "outputId": "97cd5c59-abbc-4d34-b826-aaa6bd29af21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-23 15:06:26.661122: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-23 15:06:26.812618: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-23 15:06:27.826144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uproot in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (5.1.2)\n",
            "Requirement already satisfied: awkward>=2.4.6 in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from uproot) (2.4.10)\n",
            "Requirement already satisfied: numpy in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from uproot) (1.23.3)\n",
            "Requirement already satisfied: packaging in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from uproot) (23.2)\n",
            "Requirement already satisfied: awkward-cpp==25 in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from awkward>=2.4.6->uproot) (25)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from awkward>=2.4.6->uproot) (6.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages (from importlib-metadata>=4.13.0->awkward>=2.4.6->uproot) (3.17.0)\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install uproot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muproot\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, utils, backend, callbacks\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install uproot\n",
        "import uproot\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IvPsjbMdcvYJ"
      },
      "outputs": [],
      "source": [
        "#@keras.saving.register_keras_serializable(package=\"CustomModel\", name=\"DNN2\")\n",
        "class DNN(keras.Model):\n",
        "    def __init__(self, sizes=(100, 100, 100), outputDims=2, inputDims=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self._outputShape=outputDims\n",
        "        self._denseSizes=sizes\n",
        "        self._inputShape=inputShape\n",
        "\n",
        "        self._inputs = keras.Input(shape=inputDims)\n",
        "        self._layers = []\n",
        "        for i, size in enumerate(sizes):\n",
        "            _layer = layers.Dense(size, kernel_initializer=\"he_uniform\", kernel_regularizer=keras.regularizers.L1L2(l2=1e-4))\n",
        "            _activation = layers.Activation(\"relu\")\n",
        "            self._layers.extend([_layer, _activation])\n",
        "\n",
        "        _layer = layers.Dense(outputDims)\n",
        "        _activation = layers.Activation(\"softmax\")\n",
        "        self._layers.extend([_layer, _activation])\n",
        "\n",
        "        self._outputs = self.call(self._inputs)\n",
        "        self._model = keras.Model(self._inputs, self._outputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self._tensors = [inputs]\n",
        "        for _layer in self._layers:\n",
        "            tensor = _layer(self._tensors[-1])\n",
        "            self._tensors.append(tensor)\n",
        "        return self._tensors[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sizes\": self._denseSizes,\n",
        "            \"outputDims\": self._outputShape,\n",
        "            \"inputDims\": self._inputShape,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def model(self):\n",
        "        return self._model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxEyQZoLdHiD",
        "outputId": "d8d9de9d-1d90-4445-e705-e53224637ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "            _wt        _pt      _eta      _phi  _nCharged    _girth      _ptd  \\\n",
            "0  2.664058e-09  14.526236  0.160680  5.232878          3  0.089224  0.354457   \n",
            "1  2.664058e-09  14.171301  0.034624  3.213783          2  0.039629  0.615257   \n",
            "2  2.664058e-09  10.375666  0.582861  3.944160          2  0.088296  0.528615   \n",
            "3  2.664058e-09  12.337531 -0.537796  4.923559          3  0.106382  0.370036   \n",
            "4  2.664058e-09  10.943662 -0.097477  4.372401          2  0.030195  0.501469   \n",
            "\n",
            "     _lesub  \n",
            "0  1.940472  \n",
            "1  4.263633  \n",
            "2  1.316851  \n",
            "3  0.610686  \n",
            "4  0.593166  \n",
            "            _wt        _pt      _eta      _phi  _nCharged    _girth      _ptd  \\\n",
            "0  2.664058e-09  14.522670  0.156882  5.231541          3  0.087030  0.359391   \n",
            "1  2.664058e-09  14.867034  0.034164  3.198580          2  0.045064  0.611604   \n",
            "2  2.664058e-09  11.343337  0.597785  3.944903          2  0.082767  0.523744   \n",
            "3  2.664058e-09  12.382342 -0.535900  4.923663          3  0.106021  0.370155   \n",
            "4  2.664058e-09  13.826967 -0.112214  4.367941          2  0.023728  0.500686   \n",
            "\n",
            "     _lesub  \n",
            "0  2.293354  \n",
            "1  4.156836  \n",
            "2  1.205688  \n",
            "3  0.517792  \n",
            "4  0.410006  \n",
            "train-test split Gen:  (1741723, 8) (435431, 8)\n",
            "                  _wt        _pt      _eta      _phi  _nCharged    _girth  \\\n",
            "1023902  7.551547e-13  33.274367  0.368683  1.854928          2  0.050065   \n",
            "1230475  6.914423e-14  38.154087  0.157872  3.185354          3  0.023812   \n",
            "460782   7.551547e-13  24.696322 -0.168911  0.813699          6  0.063911   \n",
            "183736   2.660543e-11  20.273283  0.311397  0.809534          3  0.104818   \n",
            "753404   7.551547e-13  17.381764  0.541204  4.206311          4  0.031511   \n",
            "\n",
            "             _ptd    _lesub  \n",
            "1023902  0.587286  5.138233  \n",
            "1230475  0.362984  1.280630  \n",
            "460782   0.201420  2.601965  \n",
            "183736   0.349962  2.078070  \n",
            "753404   0.316790  0.067367  \n",
            "                  _wt        _pt      _eta      _phi  _nCharged    _girth  \\\n",
            "236707   2.660543e-11  19.320969  0.305776  2.585159          3  0.037588   \n",
            "497491   7.551547e-13  26.416119 -0.041804  2.886845          3  0.050296   \n",
            "1099261  6.914423e-14  36.575010 -0.190866  5.702334          3  0.047551   \n",
            "522911   7.551547e-13  31.343088 -0.190673  6.263702          6  0.154222   \n",
            "133889   1.507412e-10  16.101194  0.123509  5.142933          3  0.085100   \n",
            "\n",
            "             _ptd     _lesub  \n",
            "236707   0.343174   0.467518  \n",
            "497491   0.384657   0.238807  \n",
            "1099261  0.681417  20.872177  \n",
            "522911   0.192627   2.206743  \n",
            "133889   0.338098   0.938784  \n",
            "train-test split Reco:  (1741723, 8) (435431, 8)\n",
            "                  _wt        _pt      _eta      _phi  _nCharged    _girth  \\\n",
            "1023902  7.551547e-13  17.432381  0.374540  1.929838          2  0.055209   \n",
            "1230475  6.914423e-14  39.997966  0.141105  3.188183          4  0.028843   \n",
            "460782   7.551547e-13  22.641741 -0.156114  0.826287          6  0.071340   \n",
            "183736   2.660543e-11  19.789574  0.358694  0.808039          2  0.067338   \n",
            "753404   7.551547e-13  22.562152  0.543790  4.196033          3  0.012928   \n",
            "\n",
            "             _ptd    _lesub  \n",
            "1023902  0.603062  5.772434  \n",
            "1230475  0.269129  0.591263  \n",
            "460782   0.185298  1.678634  \n",
            "183736   0.500032  0.098452  \n",
            "753404   0.468204  7.133207  \n",
            "                  _wt        _pt      _eta      _phi  _nCharged    _girth  \\\n",
            "236707   2.660543e-11  14.633199  0.314286  2.572143          2  0.021595   \n",
            "497491   7.551547e-13  20.876408 -0.053462  2.869222          2  0.036176   \n",
            "1099261  6.914423e-14  37.462004 -0.189271  5.701783          3  0.047209   \n",
            "522911   7.551547e-13  25.643145 -0.190861  6.255568          4  0.108869   \n",
            "133889   1.507412e-10  15.955902  0.123833  5.142034          3  0.084726   \n",
            "\n",
            "             _ptd     _lesub  \n",
            "236707   0.503394   0.481685  \n",
            "497491   0.618202   7.243212  \n",
            "1099261  0.686210  21.384294  \n",
            "522911   0.286351   3.185606  \n",
            "133889   0.338063   0.769171  \n",
            "Sum of training weights:  1741722.9999999998\n",
            "Sum of testing weights:  435430.99999999994\n",
            "detector-level input shapes:  (2177154, 7) (2177154, 2)\n",
            "generator-level input shapes:  (3483446, 7) (3483446, 2)\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "matches = uproot.open(\"/content/gdrive/My Drive/dataFiles/embeddingNtuples_20231023_4256.root:matches\")\n",
        "#matches.show()\n",
        "\n",
        "columns = [\"_wt\", \"_pt\", \"_eta\", \"_phi\", \"_nCharged\", \"_girth\", \"_ptd\", \"_lesub\"]\n",
        "\n",
        "reco = matches[\"recoJet\"]\n",
        "recoJets = reco.arrays(columns , library=\"pd\")\n",
        "\n",
        "gen = matches[\"genJet\"]\n",
        "genJets = gen.arrays(columns, library=\"pd\")\n",
        "\n",
        "print(recoJets.head())\n",
        "print(genJets.head())\n",
        "\n",
        "trainGen, testGen, trainReco, testReco = train_test_split(genJets, recoJets, test_size=0.2)\n",
        "\n",
        "print(\"train-test split Gen: \", trainGen.shape, testGen.shape)\n",
        "print(trainGen.head())\n",
        "print(testGen.head())\n",
        "\n",
        "print(\"train-test split Reco: \", trainReco.shape, testReco.shape)\n",
        "print(trainReco.head())\n",
        "print(testReco.head())\n",
        "\n",
        "\n",
        "trainWts = trainGen[\"_wt\"]\n",
        "trainWts = trainWts/trainWts.mean()\n",
        "print(\"Sum of training weights: \", trainWts.sum())\n",
        "\n",
        "testWts = testGen[\"_wt\"]\n",
        "testWts = testWts/testWts.mean()\n",
        "\n",
        "testGen[\"_wt\"] = testWts\n",
        "testReco[\"_wt\"] = testWts\n",
        "\n",
        "print(\"Sum of testing weights: \", testWts.sum())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "features = [\"_pt\", \"_eta\", \"_phi\", \"_nCharged\", \"_girth\", \"_ptd\", \"_lesub\"]\n",
        "\n",
        "X_det = scaler.fit_transform((pd.concat([testReco[features], trainReco[features]], ignore_index=True, sort=False)))\n",
        "X_gen = scaler.fit_transform((pd.concat([trainGen[features], trainGen[features]], ignore_index=True, sort=False)))\n",
        "\n",
        "Y_det = utils.to_categorical(np.concatenate((np.ones(testReco.shape[0]), np.zeros(trainReco.shape[0]))))\n",
        "Y_gen = utils.to_categorical(np.concatenate((np.ones(trainGen.shape[0]), np.zeros(trainGen.shape[0]))))\n",
        "\n",
        "print(\"detector-level input shapes: \", X_det.shape, Y_det.shape)\n",
        "print(\"generator-level input shapes: \", X_gen.shape, Y_gen.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFC2FnQbeafJ",
        "outputId": "147acade-bec8-4665-9004-dff2225f642e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "435430.99999999977 435430.99999999994\n",
            "435430.99999999994 1741722.9999999998\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_72 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_73 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_74 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_75 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_76 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_77 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_78 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_79 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.3198 - accuracy: 0.4849\n",
            "Epoch 1: val_loss improved from inf to 0.30083, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch1\n",
            "1742/1742 [==============================] - 19s 10ms/step - loss: 0.3198 - accuracy: 0.4850 - val_loss: 0.3008 - val_accuracy: 0.4980\n",
            "Epoch 2/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.3883\n",
            "Epoch 2: val_loss improved from 0.30083 to 0.28479, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch2\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2955 - accuracy: 0.3887 - val_loss: 0.2848 - val_accuracy: 0.5528\n",
            "Epoch 3/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.4291\n",
            "Epoch 3: val_loss improved from 0.28479 to 0.27743, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch3\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2838 - accuracy: 0.4291 - val_loss: 0.2774 - val_accuracy: 0.1995\n",
            "Epoch 4/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2791 - accuracy: 0.3781\n",
            "Epoch 4: val_loss improved from 0.27743 to 0.27510, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch4\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2791 - accuracy: 0.3780 - val_loss: 0.2751 - val_accuracy: 0.1995\n",
            "Epoch 5/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.2990\n",
            "Epoch 5: val_loss improved from 0.27510 to 0.27471, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch5\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2780 - accuracy: 0.2988 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 6/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.3264\n",
            "Epoch 6: val_loss did not improve from 0.27471\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.3263 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 7/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.4492\n",
            "Epoch 7: val_loss did not improve from 0.27471\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.4492 - val_loss: 0.2748 - val_accuracy: 0.1995\n",
            "Epoch 8/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.2713\n",
            "Epoch 8: val_loss improved from 0.27471 to 0.27468, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch8\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.2713 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 9/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.2209\n",
            "Epoch 9: val_loss improved from 0.27468 to 0.27462, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch9\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.2214 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 10/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.5583\n",
            "Epoch 10: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.5580 - val_loss: 0.2748 - val_accuracy: 0.1995\n",
            "Epoch 11/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.2053\n",
            "Epoch 11: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2059 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 12/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.4491\n",
            "Epoch 12: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.4489 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 13/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.3059\n",
            "Epoch 13: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.3058 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 14/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.2787\n",
            "Epoch 14: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2787 - val_loss: 0.2746 - val_accuracy: 0.1995\n",
            "Epoch 15/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.3906\n",
            "Epoch 15: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.3906 - val_loss: 0.2746 - val_accuracy: 0.1995\n",
            "Epoch 16/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.2703\n",
            "Epoch 16: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2703 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 17/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.3000\n",
            "Epoch 17: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.3007 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 18/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.2789\n",
            "Epoch 18: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2788 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 19/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.3255\n",
            "Epoch 19: val_loss improved from 0.27462 to 0.27462, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration0_epoch19\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.3260 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 20/50\n",
            "1737/1742 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.4658\n",
            "Epoch 20: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.4650 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 21/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.3650\n",
            "Epoch 21: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.3647 - val_loss: 0.2748 - val_accuracy: 0.1995\n",
            "Epoch 22/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.2415\n",
            "Epoch 22: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2415 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 23/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.4105\n",
            "Epoch 23: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.4104 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 24/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.2305\n",
            "Epoch 24: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.2305 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 25/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.2336\n",
            "Epoch 25: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.2336 - val_loss: 0.2746 - val_accuracy: 0.8005\n",
            "Epoch 26/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.4334\n",
            "Epoch 26: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.4330 - val_loss: 0.2748 - val_accuracy: 0.1995\n",
            "Epoch 27/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.2862\n",
            "Epoch 27: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2779 - accuracy: 0.2861 - val_loss: 0.2746 - val_accuracy: 0.1995\n",
            "Epoch 28/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.3260\n",
            "Epoch 28: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.3260 - val_loss: 0.2747 - val_accuracy: 0.1995\n",
            "Epoch 29/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.3540Restoring model weights from the end of the best epoch: 19.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.27462\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2779 - accuracy: 0.3550 - val_loss: 0.2746 - val_accuracy: 0.1995\n",
            "Epoch 29: early stopping\n",
            "218/218 [==============================] - 3s 14ms/step\n",
            "Epoch 1/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1960 - accuracy: 0.4995\n",
            "Epoch 1: val_loss improved from inf to 0.17705, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch1\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1960 - accuracy: 0.4995 - val_loss: 0.1770 - val_accuracy: 0.4999\n",
            "Epoch 2/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1743 - accuracy: 0.5004\n",
            "Epoch 2: val_loss improved from 0.17705 to 0.17173, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch2\n",
            "2787/2787 [==============================] - 31s 11ms/step - loss: 0.1743 - accuracy: 0.5004 - val_loss: 0.1717 - val_accuracy: 0.5002\n",
            "Epoch 3/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.4999\n",
            "Epoch 3: val_loss improved from 0.17173 to 0.17162, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch3\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.4999 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 4/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5002\n",
            "Epoch 4: val_loss improved from 0.17162 to 0.17162, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch4\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.5002 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 5/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.4998\n",
            "Epoch 5: val_loss improved from 0.17162 to 0.17161, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch5\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.4998 - val_loss: 0.1716 - val_accuracy: 0.5002\n",
            "Epoch 6/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.5000\n",
            "Epoch 6: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.4999 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 7/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.5001\n",
            "Epoch 7: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.5001 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 8/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.4999\n",
            "Epoch 8: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 25s 9ms/step - loss: 0.1727 - accuracy: 0.4999 - val_loss: 0.1716 - val_accuracy: 0.5002\n",
            "Epoch 9/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.4998\n",
            "Epoch 9: val_loss improved from 0.17161 to 0.17161, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration0_epoch9\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1727 - accuracy: 0.4998 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 10/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5002\n",
            "Epoch 10: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 26s 9ms/step - loss: 0.1727 - accuracy: 0.5002 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 11/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.4999\n",
            "Epoch 11: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 25s 9ms/step - loss: 0.1727 - accuracy: 0.4999 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 12/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5000\n",
            "Epoch 12: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.5000 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 13/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.4995\n",
            "Epoch 13: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1727 - accuracy: 0.4995 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 14/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5003\n",
            "Epoch 14: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1727 - accuracy: 0.5003 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 15/50\n",
            "2782/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5000\n",
            "Epoch 15: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 25s 9ms/step - loss: 0.1727 - accuracy: 0.5000 - val_loss: 0.1716 - val_accuracy: 0.5002\n",
            "Epoch 16/50\n",
            "2782/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5001\n",
            "Epoch 16: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 26s 9ms/step - loss: 0.1727 - accuracy: 0.5001 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 17/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5000\n",
            "Epoch 17: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.5000 - val_loss: 0.1716 - val_accuracy: 0.4998\n",
            "Epoch 18/50\n",
            "2782/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5000\n",
            "Epoch 18: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 25s 9ms/step - loss: 0.1727 - accuracy: 0.5000 - val_loss: 0.1716 - val_accuracy: 0.5002\n",
            "Epoch 19/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.5003Restoring model weights from the end of the best epoch: 9.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.17161\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1727 - accuracy: 0.5003 - val_loss: 0.1716 - val_accuracy: 0.5002\n",
            "Epoch 19: early stopping\n",
            "349/349 [==============================] - 7s 19ms/step\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_80 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_81 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_82 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_83 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_20 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_84 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_85 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_86 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_87 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.2878\n",
            "Epoch 1: val_loss improved from inf to 0.27664, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration1_epoch1\n",
            "1742/1742 [==============================] - 19s 10ms/step - loss: 0.2752 - accuracy: 0.2877 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 2/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.2092\n",
            "Epoch 2: val_loss did not improve from 0.27664\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.2092 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 3/50\n",
            "1737/1742 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.1999\n",
            "Epoch 3: val_loss did not improve from 0.27664\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 4/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.2577\n",
            "Epoch 4: val_loss did not improve from 0.27664\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2752 - accuracy: 0.2577 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 5/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.2352\n",
            "Epoch 5: val_loss did not improve from 0.27664\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2752 - accuracy: 0.2352 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 6/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.2326\n",
            "Epoch 6: val_loss improved from 0.27664 to 0.27659, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration1_epoch6\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2752 - accuracy: 0.2326 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 7/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.1999\n",
            "Epoch 7: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 8/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.1999\n",
            "Epoch 8: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 9/50\n",
            "1737/1742 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.1999\n",
            "Epoch 9: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 10/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.2380\n",
            "Epoch 10: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2752 - accuracy: 0.2380 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 11/50\n",
            "1737/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.1999\n",
            "Epoch 11: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 12/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.2096\n",
            "Epoch 12: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.2096 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 13/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.1999\n",
            "Epoch 13: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.1999 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 14/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.2785\n",
            "Epoch 14: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 17s 9ms/step - loss: 0.2752 - accuracy: 0.2784 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 15/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.2156\n",
            "Epoch 15: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.2156 - val_loss: 0.2767 - val_accuracy: 0.2004\n",
            "Epoch 16/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.2392Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.27659\n",
            "1742/1742 [==============================] - 16s 9ms/step - loss: 0.2752 - accuracy: 0.2391 - val_loss: 0.2766 - val_accuracy: 0.2004\n",
            "Epoch 16: early stopping\n",
            "218/218 [==============================] - 3s 15ms/step\n",
            "Epoch 1/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.5004\n",
            "Epoch 1: val_loss improved from inf to 0.17408, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration1_epoch1\n",
            "2787/2787 [==============================] - 31s 11ms/step - loss: 0.1740 - accuracy: 0.5004 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 2/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5002\n",
            "Epoch 2: val_loss improved from 0.17408 to 0.17408, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration1_epoch2\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.5002 - val_loss: 0.1741 - val_accuracy: 0.5008\n",
            "Epoch 3/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5001\n",
            "Epoch 3: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 26s 9ms/step - loss: 0.1740 - accuracy: 0.5001 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 4/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 4: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 5/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.5002\n",
            "Epoch 5: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 29s 11ms/step - loss: 0.1740 - accuracy: 0.5002 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 6/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.5002\n",
            "Epoch 6: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.5002 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 7/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5003\n",
            "Epoch 7: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 26s 9ms/step - loss: 0.1740 - accuracy: 0.5003 - val_loss: 0.1741 - val_accuracy: 0.5008\n",
            "Epoch 8/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5002\n",
            "Epoch 8: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1740 - accuracy: 0.5001 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 9/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4998\n",
            "Epoch 9: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.4998 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 10/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.4996\n",
            "Epoch 10: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 26s 9ms/step - loss: 0.1740 - accuracy: 0.4996 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 11/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5001\n",
            "Epoch 11: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.5001 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 12/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5004Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.17408\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.5004 - val_loss: 0.1741 - val_accuracy: 0.4992\n",
            "Epoch 12: early stopping\n",
            "349/349 [==============================] - 5s 14ms/step\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_88 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_89 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_90 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_91 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_92 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_93 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_94 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_95 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.3979\n",
            "Epoch 1: val_loss improved from inf to 0.27284, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration2_epoch1\n",
            "1742/1742 [==============================] - 21s 11ms/step - loss: 0.2788 - accuracy: 0.3983 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 2/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.6718\n",
            "Epoch 2: val_loss improved from 0.27284 to 0.27284, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration2_epoch2\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.6719 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 3/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.5623\n",
            "Epoch 3: val_loss did not improve from 0.27284\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.5627 - val_loss: 0.2729 - val_accuracy: 0.8008\n",
            "Epoch 4/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.6473\n",
            "Epoch 4: val_loss did not improve from 0.27284\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.6474 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 5/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.7124\n",
            "Epoch 5: val_loss improved from 0.27284 to 0.27281, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration2_epoch5\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.7116 - val_loss: 0.2728 - val_accuracy: 0.1992\n",
            "Epoch 6/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.4237\n",
            "Epoch 6: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.4239 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 7/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.5548\n",
            "Epoch 7: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.5549 - val_loss: 0.2729 - val_accuracy: 0.8008\n",
            "Epoch 8/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.6903\n",
            "Epoch 8: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.6905 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 9/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.5650\n",
            "Epoch 9: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.5653 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 10/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.7671\n",
            "Epoch 10: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.7671 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 11/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.6861\n",
            "Epoch 11: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.6859 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 12/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.5440\n",
            "Epoch 12: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 18s 11ms/step - loss: 0.2788 - accuracy: 0.5444 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 13/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.4976\n",
            "Epoch 13: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2788 - accuracy: 0.4979 - val_loss: 0.2729 - val_accuracy: 0.8008\n",
            "Epoch 14/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.6916\n",
            "Epoch 14: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.6913 - val_loss: 0.2728 - val_accuracy: 0.1992\n",
            "Epoch 15/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.6386Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.27281\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2788 - accuracy: 0.6388 - val_loss: 0.2728 - val_accuracy: 0.8008\n",
            "Epoch 15: early stopping\n",
            "218/218 [==============================] - 4s 17ms/step\n",
            "Epoch 1/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 1: val_loss improved from inf to 0.17775, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration2_epoch1\n",
            "2787/2787 [==============================] - 31s 11ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 2/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4997\n",
            "Epoch 2: val_loss improved from 0.17775 to 0.17774, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration2_epoch2\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1740 - accuracy: 0.4997 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 3/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4996\n",
            "Epoch 3: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1740 - accuracy: 0.4996 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 4/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 4: val_loss improved from 0.17774 to 0.17774, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration2_epoch4\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 5/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 5: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 6/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.4997\n",
            "Epoch 6: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4997 - val_loss: 0.1778 - val_accuracy: 0.4994\n",
            "Epoch 7/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 7: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1778 - val_accuracy: 0.4994\n",
            "Epoch 8/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 8: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 9/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.4999\n",
            "Epoch 9: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4999 - val_loss: 0.1778 - val_accuracy: 0.5006\n",
            "Epoch 10/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4998\n",
            "Epoch 10: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1740 - accuracy: 0.4998 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 11/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4998\n",
            "Epoch 11: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1740 - accuracy: 0.4998 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 12/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.5000\n",
            "Epoch 12: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1740 - accuracy: 0.5000 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 13/50\n",
            "2783/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4996\n",
            "Epoch 13: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4996 - val_loss: 0.1777 - val_accuracy: 0.5006\n",
            "Epoch 14/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 4.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.17774\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1740 - accuracy: 0.4997 - val_loss: 0.1778 - val_accuracy: 0.4994\n",
            "Epoch 14: early stopping\n",
            "349/349 [==============================] - 5s 15ms/step\n",
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_23 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 100)               800       \n",
            "                                                                 \n",
            " activation_96 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_97 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_98 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_99 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 100)               800       \n",
            "                                                                 \n",
            " activation_100 (Activation  (None, 100)               0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_101 (Activation  (None, 100)               0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_102 (Activation  (None, 100)               0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 2)                 202       \n",
            "                                                                 \n",
            " activation_103 (Activation  (None, 2)                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21202 (82.82 KB)\n",
            "Trainable params: 21202 (82.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1737/1742 [============================>.] - ETA: 0s - loss: 0.2856 - accuracy: 0.7122\n",
            "Epoch 1: val_loss improved from inf to 0.28481, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step1_iteration3_epoch1\n",
            "1742/1742 [==============================] - 21s 12ms/step - loss: 0.2856 - accuracy: 0.7124 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 2/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 2: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 3/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 3: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 4/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.8001\n",
            "Epoch 4: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 18s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 5/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 5: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 6/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 6: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 18s 10ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2849 - val_accuracy: 0.7996\n",
            "Epoch 7/50\n",
            "1741/1742 [============================>.] - ETA: 0s - loss: 0.2856 - accuracy: 0.8001\n",
            "Epoch 7: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 8/50\n",
            "1739/1742 [============================>.] - ETA: 0s - loss: 0.2856 - accuracy: 0.8001\n",
            "Epoch 8: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 18s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 9/50\n",
            "1740/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 9: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 10/50\n",
            "1738/1742 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8001\n",
            "Epoch 10: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 19s 11ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 11/50\n",
            "1742/1742 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.8001Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.28481\n",
            "1742/1742 [==============================] - 17s 10ms/step - loss: 0.2856 - accuracy: 0.8001 - val_loss: 0.2848 - val_accuracy: 0.7996\n",
            "Epoch 11: early stopping\n",
            "218/218 [==============================] - 3s 15ms/step\n",
            "Epoch 1/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.5003\n",
            "Epoch 1: val_loss improved from inf to 0.16873, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration3_epoch1\n",
            "2787/2787 [==============================] - 32s 11ms/step - loss: 0.1690 - accuracy: 0.5003 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 2/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 2: val_loss improved from 0.16873 to 0.16871, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration3_epoch2\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 3/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 3: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1689 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 4/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 4: val_loss improved from 0.16871 to 0.16871, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration3_epoch4\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 5/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5003\n",
            "Epoch 5: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 6/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 6: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 28s 10ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 7/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 7: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 11ms/step - loss: 0.1689 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 8/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 8: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1689 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 9/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 9: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1689 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 10/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 10: val_loss improved from 0.16871 to 0.16871, saving model to /content/gdrive/MyDrive/savedModels/savedModel_step2_iteration3_epoch10\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 11/50\n",
            "2787/2787 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 11: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 12/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 12: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 31s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 13/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 13: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 31s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 14/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 14: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 15/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 15: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 16/50\n",
            "2786/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004\n",
            "Epoch 16: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1689 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 17/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 17: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 30s 11ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 18/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 18: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 27s 10ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 19/50\n",
            "2784/2787 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.5004\n",
            "Epoch 19: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 20/50\n",
            "2785/2787 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.5004Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.16871\n",
            "2787/2787 [==============================] - 29s 10ms/step - loss: 0.1690 - accuracy: 0.5004 - val_loss: 0.1687 - val_accuracy: 0.4986\n",
            "Epoch 20: early stopping\n",
            "349/349 [==============================] - 5s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "nData, nEmbedding = np.count_nonzero(Y_det[:,1]), np.count_nonzero(Y_det[:,0])\n",
        "#wtest[key] = np.ones(ntest[key])\n",
        "wData = testWts.to_numpy()\n",
        "#wtrain[key] = ntest[key]/ntrain[key]*np.ones(ntrain[key])\n",
        "wEmbedding = (testWts.sum()/trainWts.sum()*trainWts).to_numpy()\n",
        "\n",
        "print(np.sum(wEmbedding), np.sum(wData))\n",
        "print(np.sum(testWts), np.sum(trainWts))\n",
        "\n",
        "#now = datetime.now()\n",
        "#nownow = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "folderPath = \"/content/gdrive/MyDrive/savedModels/savedModel_\"\n",
        "\n",
        "lossFunc=\"binary_crossentropy\"\n",
        "optimizer=\"adam\"\n",
        "metricList=[\"accuracy\"]\n",
        "\n",
        "patience=10\n",
        "\n",
        "validationSize = 0.2\n",
        "nEpochs = 50\n",
        "batchSize = 1000\n",
        "\n",
        "inputShape = X_det.shape[1:]\n",
        "\n",
        "w_sim = [wEmbedding]\n",
        "nIter = 4\n",
        "for i in range(nIter):\n",
        "  detModel = DNN(sizes=(100, 100, 100), outputDims=2, inputDims=inputShape)\n",
        "  detModel.compile(loss=lossFunc, optimizer=optimizer, metrics=metricList, weighted_metrics=[])\n",
        "  detModel.model().summary()\n",
        "  detCallBacks = [callbacks.EarlyStopping(patience=patience, verbose=1, restore_best_weights=True)]\n",
        "  detModelFilePath = folderPath + f\"step1_iteration{i}\"+\"_epoch{epoch}\"\n",
        "  detCallBacks.append(callbacks.ModelCheckpoint(detModelFilePath, save_best_only=True, verbose=1))\n",
        "\n",
        "  genModel = DNN(sizes=(100, 100, 100), outputDims=2, inputDims=inputShape)\n",
        "  genModel.compile(loss=lossFunc, optimizer=optimizer, metrics=metricList, weighted_metrics=[])\n",
        "  genModel.model().summary()\n",
        "  genCallBacks = [callbacks.EarlyStopping(patience=patience, verbose=1, restore_best_weights=True)]\n",
        "  genModelFilePath = folderPath + f\"step2_iteration{i}\"+\"_epoch{epoch}\"\n",
        "  genCallBacks.append(callbacks.ModelCheckpoint(genModelFilePath, save_best_only=True, verbose=1))\n",
        "\n",
        "  if(i > 0):\n",
        "    detModel.load_weights(folderPath + f\"step1_iteration{i-1}\")\n",
        "    genModel.load_weights(folderPath + f\"step2_iteration{i-1}\")\n",
        "\n",
        "  w_det = np.concatenate([wData, w_sim[-1]])\n",
        "\n",
        "  X_det_train, X_det_val, Y_det_train, Y_det_val, w_det_train, w_det_val = train_test_split(X_det, Y_det, w_det, test_size=validationSize)\n",
        "  detModel.fit(X_det_train, Y_det_train, sample_weight=w_det_train, epochs=nEpochs, batch_size=batchSize, validation_data=(X_det_val, Y_det_val, w_det_val), verbose=1, callbacks=detCallBacks)\n",
        "  detModel.save_weights(folderPath + f\"step1_iteration{i}\")\n",
        "  prediction = detModel.predict(X_det, batch_size=batchSize*10)\n",
        "  scaleFactors = prediction[Y_det[:, 0] == 1]\n",
        "\n",
        "  _pull = (scaleFactors[:, 1]/(scaleFactors[:, 0] + backend.epsilon()))*w_sim[-1]\n",
        "  w_sim.append(_pull)\n",
        "\n",
        "  w_gen = np.concatenate([w_sim[-1], w_sim[0]])\n",
        "\n",
        "  X_gen_train, X_gen_val, Y_gen_train, Y_gen_val, w_gen_train, w_gen_val = train_test_split(X_gen, Y_gen, w_gen, test_size=validationSize)\n",
        "  genModel.fit(X_gen_train, Y_gen_train, sample_weight=w_gen_train, epochs=nEpochs, batch_size=batchSize, validation_data=(X_gen_val, Y_gen_val, w_gen_val), verbose=1, callbacks=genCallBacks)\n",
        "  genModel.save_weights(folderPath + f\"step2_iteration{i}\")\n",
        "  prediction = genModel.predict(X_gen, batch_size=batchSize*10)\n",
        "  scaleFactors = prediction[Y_gen[:, 0] == 1]\n",
        "\n",
        "  _push = (scaleFactors[:, 1]/(scaleFactors[:, 0] + backend.epsilon()))*w_sim[-1]\n",
        "  w_sim.append(_push)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcADg-7_gBKK"
      },
      "outputs": [],
      "source": [
        "#columns = [\"_wt\", \"_pt\", \"_eta\", \"_phi\", \"_nCharged\", \"_girth\", \"_ptd\", \"_lesub\"]\n",
        "feature = \"_nCharged\"\n",
        "Min = 0.\n",
        "Max = 13.\n",
        "nBins = 12\n",
        "\n",
        "cpt1, binpt1 = np.histogram(trainGen[feature], bins=nBins, range=(Min, Max), weights=w_sim[-1], density=True)\n",
        "cpt2, binpt2 = np.histogram(testGen[feature], bins=nBins, range=(Min, Max), weights=testWts, density=True)\n",
        "cpt3, binpt3 = np.histogram(testReco[feature], bins=nBins, range=(Min, Max), weights=testWts, density=True)\n",
        "\n",
        "#crat = cpt1/cpt2\n",
        "#crat1 = cpt3/cpt2\n",
        "\n",
        "#plt.hist(binpt1[:-1], binpt1, weights=crat1)\n",
        "#plt.hist(binpt1[:-1], binpt1, weights=crat)\n",
        "\n",
        "#plt.yscale(\"log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "a5UJwI_qr_a5",
        "outputId": "d5a2c350-8c21-4e85-bb74-caaf8232c21a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.00000000e+00, 6.17528063e-01, 2.44123219e-01, 5.22937632e-02,\n",
              "        7.85359577e-03, 1.19437022e-03, 7.55672558e-05, 6.38509225e-06,\n",
              "        1.89323365e-06, 6.09715189e-08, 5.89956328e-09, 1.83898896e-10]),\n",
              " array([ 0.        ,  1.08333333,  2.16666667,  3.25      ,  4.33333333,\n",
              "         5.41666667,  6.5       ,  7.58333333,  8.66666667,  9.75      ,\n",
              "        10.83333333, 11.91666667, 13.        ]),\n",
              " <BarContainer object of 12 artists>)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(binpt1[:-1], binpt1, weights=cpt3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOGPf51rInRs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
