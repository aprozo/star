{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilv6MKqrT9sd",
        "outputId": "97cd5c59-abbc-4d34-b826-aaa6bd29af21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-20 22:21:25.672217: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-02-20 22:21:26.054707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-20 22:21:27.567742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-20 22:21:31.023011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:31.039782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:31.039831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras import layers, utils, backend, callbacks\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import modplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from hep_ml import reweight\n",
        "\n",
        "import uproot\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]) #in MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ZFit \n",
        "Returns weights for centrality 0, 1 or 2 (0-10,10-40,40-80 %)\n",
        "\n",
        "Important : (D0mass > 1.75) & (D0mass<2.0) cuts should be always applied\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/prozorov/install/miniconda3/envs/tf/lib/python3.11/site-packages/zfit/__init__.py:63: UserWarning: TensorFlow warnings are by default suppressed by zfit. In order to show them, set the environment variable ZFIT_DISABLE_TF_WARNINGS=0. In order to suppress the TensorFlow warnings AND this warning, set ZFIT_DISABLE_TF_WARNINGS=1.\n",
            "  warnings.warn(\n",
            "2024-02-20 22:21:31.645415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:31.645521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:31.645543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:33.239647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:33.239672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2024-02-20 22:21:33.239728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:33.239755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-20 22:21:33.239820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "import mplhep\n",
        "import numpy as np\n",
        "import zfit\n",
        "from matplotlib import pyplot as plt\n",
        "import uproot\n",
        "from hepstats.splot import compute_sweights\n",
        "\n",
        "obs = zfit.Space('D0mass', limits=(1.75, 2.0))\n",
        "mu = zfit.Parameter(\"mu\", 1.865, 1.8, 1.92, step_size=0.0001)\n",
        "sigma = zfit.Parameter(\"sigma\", 0.02, 0.001, 0.3, step_size=0.0001)\n",
        "lambd = zfit.Parameter(\"lambda\", -3.0)\n",
        "sig_yield = zfit.Parameter('sig_yield', 5300, 0, 100000,\n",
        "                                step_size=10)  # step size: default is small, use appropriate\n",
        "bkg_yield = zfit.Parameter('bkg_yield', 25000, 0, 3e5, step_size=10)\n",
        "\n",
        "\n",
        "def getSWeights(centrality) -> np.array:\n",
        "    centralityCut=\"\"\n",
        "    if (centrality ==0):\n",
        "        centralityCut = \"(centrality==8)\"\n",
        "    elif (centrality ==1):\n",
        "        centralityCut = \"(centrality>=5) &( centrality<8) \"\n",
        "    elif (centrality ==2):\n",
        "        centralityCut = \"(centrality <5)\"\n",
        "    else:\n",
        "        print(\"Wrong centrality\")\n",
        "        return\n",
        "\n",
        "    with uproot.open(\"/home/prozorov/dev/star/D0_jets_2014_231030.root\") as exp_file:\n",
        "          exp_tree = exp_file['Jets']\n",
        "          exp = exp_tree.arrays([\"D0mass\"], cut=centralityCut + \" & (D0mass > 1.75) & (D0mass<2.0)\",library='pd')\n",
        "    \n",
        "# model building, pdf creation\n",
        "    signal_pdf  = zfit.pdf.Gauss(mu=mu, sigma=sigma, obs=obs)\n",
        "    comb_bkg_pdf  = zfit.pdf.Exponential(lambd, obs=obs)\n",
        "\n",
        "    data= zfit.Data.from_pandas(exp)\n",
        "\n",
        "# Create the extended models\n",
        "    extended_sig = signal_pdf.create_extended(sig_yield)\n",
        "    extended_bkg = comb_bkg_pdf.create_extended(bkg_yield)\n",
        "\n",
        "# The final model is the combination of the signal and backgrond PDF\n",
        "    model = zfit.pdf.SumPDF([extended_bkg, extended_sig])\n",
        "\n",
        "# plot the data\n",
        "    data_mass = data[\"D0mass\"].numpy()\n",
        "\n",
        "# Builds the loss.\n",
        "    data_sw = zfit.Data.from_numpy(obs=obs, array=data_mass)\n",
        "    nll_sw = zfit.loss.ExtendedUnbinnedNLL(model, data_sw)\n",
        "\n",
        "# This parameter was useful in the simultaneous fit but not anymore so we fix it.\n",
        "    sigma.floating = False\n",
        "\n",
        "# Minimizes the loss.\n",
        "    minimizer = zfit.minimize.Minuit(use_minuit_grad=True)\n",
        "    result_sw = minimizer.minimize(nll_sw)\n",
        "   \n",
        "    weights = compute_sweights(model, data_sw)\n",
        "    return weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 12. 15. 18. 30.]\n",
            "[[0.8040493  0.83887934 0.91436481]\n",
            " [0.83531431 0.87066498 0.93592894]\n",
            " [0.86378964 0.89502397 0.94950428]\n",
            " [0.8858829  0.91200534 0.95879075]\n",
            " [0.90171456 0.92392761 0.96557282]\n",
            " [0.91389318 0.93324831 0.97033296]\n",
            " [0.92173535 0.94047693 0.97348525]\n",
            " [0.92743685 0.94662845 0.97777634]\n",
            " [0.93525452 0.94907014 0.97975429]\n",
            " [0.94756974 0.95762499 0.98211105]\n",
            " [0.95040946 0.96266307 0.98382422]\n",
            " [0.96602388 0.96608892 0.98780008]\n",
            " [0.96862745 0.96307934 0.99102773]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with uproot.open(\"~/dev/star/unfold/JetFinderEfficiency.root\") as fileEff:\n",
        "    fileEff.classnames()\n",
        "    JetFinderEfficiency=fileEff[\"JetFinderEfficiency\"].to_numpy()\n",
        "    print(JetFinderEfficiency[1])\n",
        "    print(JetFinderEfficiency[0])\n",
        "\n",
        "def getEfficiencyPtWeight(pt):\n",
        "    ptBin = np.digitize(pt, JetFinderEfficiency[1])-1\n",
        "    if (ptBin<0):\n",
        "        ptBin=0\n",
        "    elif (ptBin>=len(JetFinderEfficiency[0])):\n",
        "        ptBin=len(JetFinderEfficiency[0])-1\n",
        "    return JetFinderEfficiency[0][ptBin]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define default plot styles  \n",
        "\n",
        "from matplotlib import rc\n",
        "import matplotlib.font_manager\n",
        "\n",
        "rc('font', family='serif')\n",
        "rc('text', usetex=False)\n",
        "rc('font', size=22)\n",
        "rc('xtick', labelsize=15)\n",
        "rc('ytick', labelsize=15)\n",
        "rc('legend', fontsize=15)\n",
        "\n",
        "plot_style_0 = {\n",
        "    'histtype': 'step',\n",
        "    'color': 'black',\n",
        "    'linewidth': 2,\n",
        "    'linestyle': '--',\n",
        "    'density': False\n",
        "}\n",
        "\n",
        "plot_style_1 = {\n",
        "    'histtype': 'step',\n",
        "    'color': 'black',\n",
        "    'linewidth': 2,\n",
        "    'density': False\n",
        "}\n",
        "\n",
        "plot_style_2 = {'alpha': 0.5, 'density': False}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IvPsjbMdcvYJ"
      },
      "outputs": [],
      "source": [
        "#@keras.saving.register_keras_serializable(package=\"CustomModel\", name=\"DNN2\")\n",
        "class DNN(keras.Model):\n",
        "    def __init__(self, sizes=(100, 100, 100), outputDims=2, inputDims=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self._outputShape=outputDims\n",
        "        self._denseSizes=sizes\n",
        "        self._inputShape=inputShape\n",
        "\n",
        "        self._inputs = keras.Input(shape=inputDims)\n",
        "        self._layers = []\n",
        "        for i, size in enumerate(sizes):\n",
        "            _layer = layers.Dense(size, kernel_initializer=\"he_uniform\", kernel_regularizer=keras.regularizers.L1L2(l2=1e-4))\n",
        "            _activation = layers.Activation(\"relu\")\n",
        "            self._layers.extend([_layer, _activation])\n",
        "\n",
        "        _layer = layers.Dense(outputDims)\n",
        "        _activation = layers.Activation(\"softmax\")\n",
        "        self._layers.extend([_layer, _activation])\n",
        "\n",
        "        self._outputs = self.call(self._inputs)\n",
        "        self._model = keras.Model(self._inputs, self._outputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self._tensors = [inputs]\n",
        "        for _layer in self._layers:\n",
        "            tensor = _layer(self._tensors[-1])\n",
        "            self._tensors.append(tensor)\n",
        "        return self._tensors[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sizes\": self._denseSizes,\n",
        "            \"outputDims\": self._outputShape,\n",
        "            \"inputDims\": self._inputShape,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def model(self):\n",
        "        return self._model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Centrality',\n",
              " 'Weight',\n",
              " 'RefMult',\n",
              " 'gRefMult',\n",
              " 'RefCorr2',\n",
              " 'McRefMult',\n",
              " 'RecoRefMult',\n",
              " 'McD0Pt',\n",
              " 'McD0Eta',\n",
              " 'McD0Phi',\n",
              " 'McPionPt',\n",
              " 'McPionEta',\n",
              " 'McPionPhi',\n",
              " 'McKaonPt',\n",
              " 'McKaonEta',\n",
              " 'McKaonPhi',\n",
              " 'RecoD0Pt',\n",
              " 'RecoD0Eta',\n",
              " 'RecoD0Phi',\n",
              " 'RecoPionPt',\n",
              " 'RecoPionEta',\n",
              " 'RecoPionPhi',\n",
              " 'RecoKaonPt',\n",
              " 'RecoKaonEta',\n",
              " 'RecoKaonPhi',\n",
              " 'McJetPt',\n",
              " 'McJetEta',\n",
              " 'McJetPhi',\n",
              " 'McJetArea',\n",
              " 'McJetE',\n",
              " 'McJetNConst',\n",
              " 'McJetLambda_1_1',\n",
              " 'McJetLambda_1_1half',\n",
              " 'McJetLambda_1_2',\n",
              " 'McJetLambda_1_3',\n",
              " 'McJetD0Z',\n",
              " 'McRecoJetPt',\n",
              " 'McRecoJetEta',\n",
              " 'McRecoJetPhi',\n",
              " 'McRecoJetE',\n",
              " 'McRecoJetArea',\n",
              " 'McRecoJetNConst',\n",
              " 'McRecoJetLambda_1_1',\n",
              " 'McRecoJetLambda_1_1half',\n",
              " 'McRecoJetLambda_1_2',\n",
              " 'McRecoJetLambda_1_3',\n",
              " 'McRecoJetD0Z',\n",
              " 'RecoJetPt',\n",
              " 'RecoJetEta',\n",
              " 'RecoJetPhi',\n",
              " 'RecoJetArea',\n",
              " 'RecoJetE',\n",
              " 'RecoJetRhoVal',\n",
              " 'RecoJetNConst',\n",
              " 'RecoJetLambda_1_1',\n",
              " 'RecoJetLambda_1_1half',\n",
              " 'RecoJetLambda_1_2',\n",
              " 'RecoJetLambda_1_3',\n",
              " 'RecoJetD0Z']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trees = [uproot.open(\"/home/prozorov/dev/star/output_jets.root:Jets\"), ]\n",
        "\n",
        "trees[0].keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "centrality=trees[0][\"Centrality\"].array()\n",
        "plt.hist(centrality, bins=np.linspace(0, 80, 9), **plot_style_0)\n",
        "plt.xlabel(\"Centrality,%\")\n",
        "plt.ylabel(\"Counts\")\n",
        "\n",
        "centralityBins=[0,10,40,80]\n",
        "plt.hist(centrality, bins=centralityBins, **plot_style_2)\n",
        "plt.show()\n",
        "\n",
        "centralityCuts = [\"(Centrality > {}) & (Centrality < {})\".format(centralityBins[i], centralityBins[i+1]) for i in range(len(centralityBins)-1)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = [\"pt\", \"z\", \"lambda_1_1\", \"lambda_1_1half\", \"lambda_1_2\", \"lambda_1_3\"]\n",
        "\n",
        "with uproot.open(\"/home/prozorov/dev/star/output_jets.root\") as original_file:\n",
        "    original_tree = original_file['Jets']\n",
        "    sim = original_tree.arrays([\"RecoJetPt\",\"RecoJetD0Z\",\"RecoJetLambda_1_1\",\n",
        "                            \"RecoJetLambda_1_1half\",\"RecoJetLambda_1_2\",\n",
        "                            \"RecoJetLambda_1_3\"], cut=\"(RecoJetNConst>0) & (Centrality<10)\", library='pd', entry_stop=1000000)\n",
        "    \n",
        "    sim.rename(columns={\"RecoJetPt\": \"pt\", \"RecoJetD0Z\": \"z\",  \"RecoJetLambda_1_1\": \"lambda_1_1\", \"RecoJetLambda_1_1half\": \"lambda_1_1half\", \"RecoJetLambda_1_2\": \"lambda_1_2\", \"RecoJetLambda_1_3\": \"lambda_1_3\"}, inplace=True)\n",
        "    \n",
        "with uproot.open(\"/home/prozorov/dev/star/D0_jets_2014_231030.root\") as target_file:\n",
        "    target_tree = target_file['Jets']\n",
        "    exp = target_tree.arrays([\"jet_pt_corr\",\"z\", \"lambda_1_1\",\"lambda_1_1half\",\"lambda_1_2\",\"lambda_1_3\"], cut=\"centrality==8\",library='pd')\n",
        "    exp.rename(columns={\"jet_pt_corr\": \"pt\"}, inplace=True)\n",
        "\n",
        "original_weights = np.ones(len(sim))\n",
        "\n",
        "# divide original samples into training ant test parts\n",
        "original_train, original_test = train_test_split(sim)\n",
        "# divide target samples into training ant test parts\n",
        "target_train, target_test = train_test_split(exp)\n",
        "\n",
        "original_weights_train = np.ones(len(original_train))\n",
        "original_weights_test = np.ones(len(original_test))\n",
        "\n",
        "from hep_ml.metrics_utils import ks_2samp_weighted\n",
        "\n",
        "hist_settings = {'bins': 50, 'density': True, 'alpha': 0.7}\n",
        "\n",
        "\n",
        "def draw_distributions(original, target, new_original_weights):\n",
        "    plt.figure(figsize=[15, 7])\n",
        "    for id, column in enumerate(columns, 1):\n",
        "        xlim = np.percentile(np.hstack([target[column]]), [1, 99])\n",
        "        plt.subplot(2, 3, id)\n",
        "        plt.hist(original[column], weights=new_original_weights, range=xlim, **hist_settings)\n",
        "        plt.hist(target[column], range=xlim, **hist_settings)\n",
        "        plt.yscale('log')\n",
        "        plt.title(column)\n",
        "        print('KS over ', column, ' = ', ks_2samp_weighted(original[column], target[column],\n",
        "                                         weights1=new_original_weights, weights2=np.ones(len(target), dtype=float)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'original' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m draw_distributions(\u001b[43moriginal\u001b[49m, target, original_weights)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'original' is not defined"
          ]
        }
      ],
      "source": [
        "draw_distributions(original, target, original_weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw_distributions(original_train, target_train, original_weights_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "draw_distributions(original_test, target_test, original_weights_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# define base reweighter\n",
        "reweighter_base = reweight.GBReweighter(n_estimators=100, \n",
        "                                        learning_rate=0.1, max_depth=3, min_samples_leaf=1000, \n",
        "                                        gb_args={'subsample': 0.4})\n",
        "reweighter = reweight.FoldingReweighter(reweighter_base, n_folds=3)\n",
        "# it is not needed divide data into train/test parts; reweighter can be train on the whole samples\n",
        "reweighter.fit(original, target)\n",
        "\n",
        "folding_weights  = reweighter.predict_weights(original)\n",
        "# validate reweighting rule on the test part comparing 1d projections\n",
        "draw_distributions(original, target, folding_weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(gb_weights_test, bins=50)\n",
        "plt.yscale('log')\n",
        "plt.title('predicted weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxEyQZoLdHiD",
        "outputId": "d8d9de9d-1d90-4445-e705-e53224637ce2"
      },
      "outputs": [],
      "source": [
        "\n",
        "trees = [uproot.open(\"/home/prozorov/dev/star/output_jets.root:Jets\")]\n",
        "centralityBins=[0,80]\n",
        "centralityCuts = [\"(Centrality >= {}) & (Centrality < {})\".format(centralityBins[i], centralityBins[i+1]) for i in range(len(centralityBins)-1)]\n",
        "nEvents=100000\n",
        "\n",
        "features = [ \"pt\",\"z\" , \"lambda_1_1\", \"lambda_1_1half\",\"lambda_1_2\",\"lambda_1_3\"]\n",
        "\n",
        "# make centrality dependent analysis\n",
        "\n",
        "for i in range(len(centralityCuts)):\n",
        "  print(\"Processing centrality bin: \", centralityCuts[i])\n",
        "  \n",
        "  sim_mc_reco= trees[0].arrays([\"McJetPt\", \"McJetD0Z\", \n",
        "                               \"McJetLambda_1_1\", \"McJetLambda_1_1half\",\"McJetLambda_1_2\",\"McJetLambda_1_3\", \n",
        "                              \"RecoJetPt\",\"RecoJetD0Z\",\n",
        "                               \"RecoJetLambda_1_1\", \"RecoJetLambda_1_1half\",\"RecoJetLambda_1_2\",\"RecoJetLambda_1_3\",\"RecoJetNConst\"\n",
        "                            ],   \n",
        "                              cut=centralityCuts[i], library=\"pd\", entry_stop=nEvents)\n",
        "        \n",
        "  genJets = sim_mc_reco.iloc[:,0:6]\n",
        "  recoJets = sim_mc_reco.iloc[:,6:13]\n",
        "  genJets.rename(columns={\"McJetPt\": \"pt\", \"McJetD0Z\": \"z\",  \"McJetLambda_1_1\": \"lambda_1_1\", \"McJetLambda_1_1half\": \"lambda_1_1half\", \"McJetLambda_1_2\": \"lambda_1_2\", \"McJetLambda_1_3\": \"lambda_1_3\"}, inplace=True)\n",
        "  recoJets.rename(columns={\"RecoJetPt\": \"pt\", \"RecoJetD0Z\": \"z\" , \"RecoJetLambda_1_1\": \"lambda_1_1\", \"RecoJetLambda_1_1half\": \"lambda_1_1half\", \"RecoJetLambda_1_2\": \"lambda_1_2\", \"RecoJetLambda_1_3\": \"lambda_1_3\"}, inplace=True)\n",
        "\n",
        "  dummyval=-99\n",
        "  mask = recoJets[\"RecoJetNConst\"] == 0\n",
        "  recoJets.loc[mask,features[0]:features[-1]] = dummyval\n",
        "\n",
        "  print(recoJets.head(20))\n",
        "  print(genJets.head(20))\n",
        "\n",
        "  trainGen, testGen, trainReco, testReco = train_test_split(genJets, recoJets, test_size=0.2)\n",
        "\n",
        "  trainWts = np.ones(trainGen.shape[0])\n",
        "  print(\"Sum of training weights: \", trainWts.sum())\n",
        "\n",
        "  testWts = np.ones(testGen.shape[0])\n",
        "  print(\"Sum of testing weights: \", testWts.sum())\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  X_det = scaler.fit_transform(pd.concat([testReco[features], trainReco[features]], ignore_index=True, sort=False))\n",
        "  X_gen = scaler.fit_transform(pd.concat([trainGen[features], trainGen[features]], ignore_index=True, sort=False))\n",
        "\n",
        "  Y_det = utils.to_categorical(np.concatenate( (np.ones(testReco.shape[0]), np.zeros(trainReco.shape[0])) ))\n",
        "  Y_gen = utils.to_categorical(np.concatenate( (np.ones(trainGen.shape[0]), np.zeros(trainGen.shape[0])) ))\n",
        "\n",
        "  print(\"detector-level input shapes: \", X_det.shape, Y_det.shape)\n",
        "  print(\"generator-level input shapes: \", X_gen.shape, Y_gen.shape)\n",
        "\n",
        "\n",
        "  print(\"X_det.head(): \", X_det[0:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFC2FnQbeafJ",
        "outputId": "147acade-bec8-4665-9004-dff2225f642e"
      },
      "outputs": [],
      "source": [
        "nData, nEmbedding = np.count_nonzero(Y_det[:,1]), np.count_nonzero(Y_det[:,0])\n",
        "#wtest[key] = np.ones(ntest[key])\n",
        "wData = testWts\n",
        "#wtrain[key] = ntest[key]/ntrain[key]*np.ones(ntrain[key])\n",
        "wEmbedding = (testWts.sum()/trainWts.sum()*trainWts)\n",
        "\n",
        "print(np.sum(wEmbedding), np.sum(wData))\n",
        "print(np.sum(testWts), np.sum(trainWts))\n",
        "\n",
        "folderPath = \"./weights/savedModel_\"\n",
        "\n",
        "lossFunc=\"binary_crossentropy\"\n",
        "optimizer=\"adam\"\n",
        "metricList=[\"accuracy\"]\n",
        "\n",
        "validationSize = 0.2\n",
        "nEpochs = 50\n",
        "batchSize = 1000\n",
        "\n",
        "inputShape = X_det.shape[1:]\n",
        "\n",
        "w_sim = [wEmbedding]\n",
        "nIter = 2\n",
        "earlystopping = EarlyStopping(patience=10,\n",
        "                              verbose=1,\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# reweight the sim and data to have the same total weight to begin with\n",
        "nData, nEmbedding = np.count_nonzero(Y_det[:,1]), np.count_nonzero(Y_det[:,0])\n",
        "\n",
        "#wData = np.ones(nData)\n",
        "#wEmbedding = nData/float(nEmbedding)*np.ones(nEmbedding)\n",
        "\n",
        "wData = testWts.to_numpy()\n",
        "wEmbedding = (np.sum(wData)/trainWts.sum()*trainWts).to_numpy()\n",
        "\n",
        "print(np.sum(wEmbedding), np.sum(wData))\n",
        "print(np.sum(testWts), np.sum(trainWts))\n",
        "\n",
        "plt.hist(trainGen[\"pt\"], bins=30, weights=wEmbedding)\n",
        "plt.hist(trainReco[\"pt\"], bins=30, weights=wEmbedding)\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "now = datetime.now()\n",
        "nownow = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "folderPath = \"savedModels/savedModel_\"+nownow\n",
        "unfoldingWeightsFilename = f\"{folderPath}/unfoldingWeights\"\n",
        "#logdir = \"logs/\"+nownow\n",
        "\n",
        "lossFunc=\"categorical_crossentropy\"\n",
        "optimizer=\"adam\"\n",
        "metricList=[\"accuracy\"]\n",
        "#weightedMetricList = [\"categorical_crossentropy\"]\n",
        "weightedMetricList = []\n",
        "\n",
        "patience=5\n",
        "\n",
        "validationSize = 0.2\n",
        "nEpochs = 150\n",
        "batchSize = 2048\n",
        "\n",
        "inputShape = X_det.shape[1:]\n",
        "\n",
        "det_history = []\n",
        "gen_history = []\n",
        "w_sim = [wEmbedding]\n",
        "nIter = 10\n",
        "\n",
        "weightClipMin = 0.\n",
        "weightClipMax = np.inf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(nIter):\n",
        "    detModel = sequentialDNNMaker(input_shape=inputShape)\n",
        "    detModel.compile(loss=lossFunc, optimizer=optimizer, metrics=metricList, weighted_metrics=weightedMetricList)\n",
        "    detCallBacks = [callbacks.EarlyStopping(patience=patience, verbose=1, restore_best_weights=True)]\n",
        "    detModelFilePath = folderPath + f\"/step1_iteration{i}\"+\"_epoch{epoch}\"\n",
        "    detCallBacks.append(callbacks.ModelCheckpoint(detModelFilePath, save_best_only=True, verbose=1))\n",
        "    #detCallBacks.append(callbacks.TensorBoard(log_dir=logdir, histogram_freq=1))\n",
        "\n",
        "    genModel = sequentialDNNMaker(input_shape=inputShape)\n",
        "    genModel.compile(loss=lossFunc, optimizer=optimizer, metrics=metricList, weighted_metrics=weightedMetricList)\n",
        "    genCallBacks = [callbacks.EarlyStopping(patience=patience, verbose=1, restore_best_weights=True)]\n",
        "    genModelFilePath = folderPath + f\"/step2_iteration{i}\"+\"_epoch{epoch}\"\n",
        "    genCallBacks.append(callbacks.ModelCheckpoint(genModelFilePath, save_best_only=True, verbose=1))\n",
        "    #genCallBacks.append(callbacks.TensorBoard(log_dir=logdir, histogram_freq=1))\n",
        "\n",
        "    if(i > 0):\n",
        "        detModel.load_weights(folderPath + f\"/step1_iteration{i-1}\")\n",
        "        genModel.load_weights(folderPath + f\"/step2_iteration{i-1}\")\n",
        "\n",
        "    w_det = np.concatenate([wData, w_sim[-1]])\n",
        "    \n",
        "    X_det_train, X_det_val, Y_det_train, Y_det_val, w_det_train, w_det_val = train_test_split(X_det, Y_det, w_det, test_size=validationSize)\n",
        "    detModel.summary()\n",
        "    det_history.append(detModel.fit(X_det_train, Y_det_train, sample_weight=w_det_train, epochs=nEpochs, batch_size=batchSize, validation_data=(X_det_val, Y_det_val, w_det_val), verbose=1, callbacks=detCallBacks))\n",
        "    detModel.save_weights(folderPath + f\"/step1_iteration{i}\")\n",
        "    \n",
        "    prediction = detModel.predict(X_det, batch_size=batchSize*10)\n",
        "    scaleFactors = prediction[Y_det[:, 0] == 1]\n",
        "\n",
        "    _pull = np.clip(scaleFactors[:, 1]/(scaleFactors[:, 0]+ 10**-50), weightClipMin, weightClipMax)*w_sim[-1]\n",
        "    w_sim.append(_pull)\n",
        "\n",
        "    w_gen = np.concatenate([w_sim[-1], w_sim[-2]])\n",
        "    \n",
        "    X_gen_train, X_gen_val, Y_gen_train, Y_gen_val, w_gen_train, w_gen_val = train_test_split(X_gen, Y_gen, w_gen, test_size=validationSize)\n",
        "    genModel.summary()\n",
        "    gen_history.append(genModel.fit(X_gen_train, Y_gen_train, sample_weight=w_gen_train, epochs=nEpochs, batch_size=5*batchSize, validation_data=(X_gen_val, Y_gen_val, w_gen_val), verbose=1, callbacks=genCallBacks))\n",
        "    genModel.save_weights(folderPath + f\"/step2_iteration{i}\")\n",
        "    \n",
        "    prediction = genModel.predict(X_gen, batch_size=batchSize*50)\n",
        "    scaleFactors = prediction[Y_gen[:, 0] == 1]\n",
        "\n",
        "    _push = np.clip(scaleFactors[:, 1]/(scaleFactors[:, 0]+ 10**-50), weightClipMin, weightClipMax)*w_sim[-1]\n",
        "    w_sim.append(_push)\n",
        "    \n",
        "    np.save(unfoldingWeightsFilename, w_sim)\n",
        "\n",
        "#filename = f\"outputs/multifoldClosure_{patience}_{batchSize}_{nEpochs}_{nIter}_{nownow}.root\"\n",
        "#outFile = uproot.recreate(filename)\n",
        "#print(\"Saving to file: \", filename)\n",
        "\n",
        "#trainGen[\"wt\"] = w_sim[2*nIter]\n",
        "#outFile[\"unfolded\"] = trainGen\n",
        "#outFile[\"reco\"] = testReco\n",
        "#outFile[\"gen\"] = testGen\n",
        "wu=w_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "plt.rcParams['figure.dpi'] = 240\n",
        "plt.rcParams.update({\n",
        "    \"text.usetex\": True,\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.sans-serif\": \"Helvetica\",\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a dictionary to hold information about the observables\n",
        "obs = {}\n",
        "# the jet mass and histogram style information\n",
        "obs.setdefault('pt', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (-1, 30),  'ylim': (0.00000001, 0.3),\n",
        "    'xlabel': r'Jet $p_{t}$  [GeV/c]', 'symbol': r'$p_{t}$',\n",
        "    'ylabel': r'Counts', 'yscale': 'log',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "# the groomed momentum fraction and histogram style information\n",
        "obs.setdefault('z', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (0.1, 1.001),   'ylim': (0, 10),\n",
        "    'xlabel': r'Jet Momentum Fraction $z$', 'symbol': r'$z$',\n",
        "    'ylabel': r'Counts',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "obs.setdefault('lambda_1_1', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (0, 0.8),  'ylim': (0, 10),\n",
        "    'xlabel': r'Jet Angularity $\\lambda_{1}^{1}$', 'symbol': r'$lambda_1_1$',\n",
        "    'ylabel': r'Counts',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "obs.setdefault('lambda_1_1half', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (0, 0.4),  'ylim': (0, 10),\n",
        "    'xlabel': r'Jet Angularity $\\lambda_{1}^{1/2}$', 'symbol': r'$lambda_1_1half$',\n",
        "    'ylabel': r'Counts',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "obs.setdefault('lambda_1_2', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (0, 0.2),  'ylim': (0, 10),\n",
        "    'xlabel': r'Jet Angularity $\\lambda_{1}^{2}$', 'symbol': r'$lambda_1_2$',\n",
        "    'ylabel': r'Counts',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "obs.setdefault('lambda_1_3', {}).update({\n",
        "    'func': lambda dset, type: dset[type],\n",
        "    'nbins_det': 20, 'nbins_mc': 50,\n",
        "    'xlim': (0, 0.1),  'ylim': (0, 10),\n",
        "    'xlabel': r'Jet Angularity $\\lambda_{1}^{3}$', 'symbol': r'$lambda_1_3$',\n",
        "    'ylabel': r'Counts',\n",
        "    'stamp_xy': (0.425, 0.65),\n",
        "})\n",
        "\n",
        "\n",
        "# additional histogram and plot style information\n",
        "hist_style = {'histtype': 'step', 'density': True, 'lw': 1, 'zorder': 2}\n",
        "gen_style = {'linestyle': '--', 'color': 'blue', 'lw': 1.15, 'label': 'Gen.'}\n",
        "truth_style = {'step': 'mid', 'edgecolor': 'green', 'facecolor': (0.75, 0.875, 0.75),\n",
        "               'lw': 1.25, 'zorder': 0, 'label': '``Truth\\\"'}\n",
        "omnifold_style = {'ls': '-', 'marker': 's', 'ms': 2.5, 'color': 'tab:red', 'zorder': 3}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Unfolding Results\n",
        "\n",
        "Now it's time to plot the unfolding results for all of the specified observables!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for obkey,ob in obs.items():\n",
        "        # calculate observable for GEN, SIM, DATA\n",
        "    ob['genobs'] = trainGen[obkey].to_numpy()\n",
        "    ob['simobs'] = trainReco[obkey].to_numpy()\n",
        "\n",
        "    ob['truthobs'] = testGen[obkey].to_numpy()\n",
        "    ob['dataobs'] = testReco[obkey].to_numpy()\n",
        "\n",
        " # setup bins\n",
        "    ob['bins_det'] = np.linspace(ob['xlim'][0], ob['xlim'][1], ob['nbins_det']+1)\n",
        "    ob['bins_mc'] = np.linspace(ob['xlim'][0], ob['xlim'][1], ob['nbins_mc']+1)\n",
        "    ob['midbins_det'] = (ob['bins_det'][:-1] + ob['bins_det'][1:])/2\n",
        "    ob['midbins_mc'] = (ob['bins_mc'][:-1] + ob['bins_mc'][1:])/2\n",
        "    ob['binwidth_det'] = ob['bins_det'][1] - ob['bins_det'][0]\n",
        "    ob['binwidth_mc'] = ob['bins_mc'][1] - ob['bins_mc'][0]\n",
        "\n",
        "\n",
        "\n",
        "    # get the histograms of GEN, DATA, and SIM level observables\n",
        "    ob['genobs_hist'] = np.histogram(ob['genobs'], bins=ob['bins_mc'])[0]\n",
        "    ob['simobs_hist'] = np.histogram(ob['simobs'], bins=ob['bins_det'])[0]\n",
        "    ob['data_hist']   = np.histogram(ob['dataobs'], bins=ob['bins_det'])[0]\n",
        "  \n",
        "    ob['truth_hist'], ob['truth_hist_unc'] = modplot.calc_hist(ob['truthobs'], bins=ob['bins_mc'], \n",
        "                                                               density=True)[:2]\n",
        "  \n",
        "   \n",
        "    print('Done with', obkey)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i,(obkey,ob) in enumerate(obs.items()):\n",
        "    \n",
        "    # get the styled axes on which to plot\n",
        "    fig, [ax0, ax1] = modplot.axes(**ob)\n",
        "    if ob.get('yscale') is not None:\n",
        "        ax0.set_yscale(ob['yscale'])\n",
        "\n",
        "\n",
        "    # Plot the Different Distributions of the Observable\n",
        "    # plot the \"data\" histogram of the observable\n",
        "    ax0.hist(ob['dataobs'], bins=ob['bins_det'], color='black', label='``Data\\\"', **hist_style)\n",
        "\n",
        "    # plot the \"sim\" histogram of the observable\n",
        "    ax0.hist(ob['simobs'], bins=ob['bins_det'], color='orange', label='Sim.', **hist_style)\n",
        "\n",
        "\n",
        "    ax0.hist(ob['genobs'], bins=ob['bins_mc'], color='blue', label='``Gen\\\"', **hist_style)\n",
        "\n",
        "    # plot the \"sim\" histogram of the observable\n",
        "    ax0.hist(ob['truthobs'], bins=ob['bins_mc'], color='green', label='Truth.', **hist_style)\n",
        "\n",
        "\n",
        "    # # plot the \"gen\" histogram of the observable\n",
        "    # ax0.plot(ob['midbins_mc'], ob['genobs_hist'], **gen_style)\n",
        "\n",
        "    # plot the \"truth\" histogram of the observable\n",
        "    ax0.fill_between(ob['midbins_mc'], ob['truth_hist'], **truth_style)\n",
        "\n",
        "    \n",
        "    # Plot the Unfolded Distributions of the Observable\n",
        "    # plot the OmniFold distribution\n",
        "    of_histgen, of_histgen_unc = modplot.calc_hist(ob['genobs'], weights=w_sim[-1],\n",
        "                                                   bins=ob['bins_mc'], density=True)[:2]\n",
        "    ax0.plot(ob['midbins_mc'], of_histgen, **omnifold_style, label='MultiFold')\n",
        "\n",
        "    # Plot the Ratios of the OmniFold distribution to truth (with statistical uncertainties)\n",
        "\n",
        "    of_ratio = of_histgen/(ob['truth_hist']+ 10**-50)\n",
        "    ax1.plot(ob['midbins_mc'], of_ratio, **omnifold_style)\n",
        "\n",
        "    ax1.plot([np.min(ob['midbins_mc']), np.max(ob['midbins_mc'])], [1, 1], '-', color='green', lw=0.75)\n",
        "    \n",
        "    # ratio uncertainties\n",
        "    truth_unc_ratio = ob['truth_hist_unc']/(ob['truth_hist'] + 10**-50)\n",
        "\n",
        "    of_unc_ratio = of_histgen_unc/(ob['truth_hist'] + 10**-50)\n",
        "    \n",
        "    ax1.fill_between(ob['midbins_mc'], 1 - truth_unc_ratio, 1 + truth_unc_ratio, \n",
        "                     facecolor=truth_style['facecolor'], zorder=-2)\n",
        "\n",
        "    ax1.errorbar(ob['midbins_mc'], of_ratio, xerr=ob['binwidth_mc']/2, yerr=of_unc_ratio, \n",
        "                                              color=omnifold_style['color'], **modplot.style('errorbar'))\n",
        "\n",
        "    # legend style and ordering\n",
        "    loc, ncol = ob.get('legend_loc', 'upper right'), ob.get('legend_ncol', 2)\n",
        "    order = [3, 2, 0, 1] if ncol==2 else [3, 0, 2, 1]\n",
        "    modplot.legend(ax=ax0, frameon=False, loc=loc, ncol=ncol)\n",
        "\n",
        "    # stamp to put on the plots\n",
        "    modplot.stamp(*ob['stamp_xy'], delta_y=0.06, ax=ax0,\n",
        "                  line_0=r'\\textbf{test}'\n",
        ")\n",
        "\n",
        "\n",
        "    # save plot (by default in the same directory as this notebook).\n",
        "    # If running on binder, the plot can be accessed by first going to the jupyter file browser\n",
        "    # (which itself can be accessed by copying the URL of this notebook and removing the name of the notebook\n",
        "    # after the final \"/\"), selecting the square next to the name of the plot, and clicking \"Download\".\n",
        "    fig.savefig('MultiFold_{}.pdf'.format(obkey), bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_iter = 6\n",
        "nRows = 3\n",
        "nColumns = 3\n",
        "fig, ax = plt.subplots(nRows, nColumns, figsize=(30., 30.))\n",
        "for i, feature in enumerate(featuresNoWt):\n",
        "    row = int(i/nColumns)\n",
        "    column = i%nColumns \n",
        "        \n",
        "    histGen, bins = np.histogram(testGen[feature], weights=wData, density=True)\n",
        "    histReco, bins = np.histogram(testReco[feature], weights=wData, density=True) \n",
        "    histUnfolded, bins = np.histogram(trainGen[feature], weights=wu[2*_iter], density=True)\n",
        "        \n",
        "    ax[row, column].hist(bins[:-1], bins, weights=histReco/histGen, label=\"Reco/Gen\", histtype=\"step\")\n",
        "    ax[row, column].hist(bins[:-1], bins, weights=histUnfolded/histGen, label=\"Unfolded/Gen\", histtype=\"step\")\n",
        "    ax[row, column].hist(bins[:-1], bins, weights=np.ones((bins.shape[0]-1)), histtype=\"step\")\n",
        "    ax[row, column].set_title(feature)\n",
        "    ax[row, column].set_ylim(0.5, 1.5)\n",
        "    ax[row, column].legend(prop={'size': 15})\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_nIter = 10\n",
        "\n",
        "#metrics = [\"loss\", \"accuracy\", \"categorical_crossentropy\"]\n",
        "metrics = [\"loss\", \"accuracy\"]\n",
        "detfig, detax = plt.subplots(len(metrics), _nIter, figsize=(_nIter*5., len(metrics)*5.))\n",
        "for row, metricName in enumerate(metrics):\n",
        "    for column in range(_nIter):\n",
        "        detax[row, column].plot(det_history[column].history[metricName], label=\"training\")\n",
        "        detax[row, column].plot(det_history[column].history[\"val_\"+metricName], label=\"validation\")\n",
        "        detax[row, column].set_title(metricName+f\", detector level, iteration={column+1}\")\n",
        "        #detax[row, column].set_ylim(0.25, 0.32)\n",
        "        detax[row, column].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genfig, genax = plt.subplots(len(metrics), _nIter, figsize=(_nIter*5., len(metrics)*5.))\n",
        "for row, metricName in enumerate(metrics):\n",
        "    for column in range(_nIter):\n",
        "        genax[row, column].plot(gen_history[column].history[metricName], label=\"training\")\n",
        "        genax[row, column].plot(gen_history[column].history[\"val_\"+metricName], label=\"validation\")\n",
        "        genax[row, column].set_title(metricName+f\", gen level, iteration={column+1}\")\n",
        "        genax[row, column].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(det_history[0].history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
